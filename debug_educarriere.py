#!/usr/bin/env python3
"""
Debug script pour analyser la structure HTML d'Educarriere.ci
"""

import requests
from bs4 import BeautifulSoup
import json
import re

def debug_educarriere():
    """Debug de la page Educarriere"""

    url = "https://emploi.educarriere.ci/nos-offres"
    headers = {
        'User-Agent': 'Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36',
        'Accept': 'text/html,application/xhtml+xml,application/xml;q=0.9,*/*;q=0.8',
        'Accept-Language': 'fr-FR,fr;q=0.9,en;q=0.8',
        'Accept-Encoding': 'gzip, deflate, br',
        'DNT': '1',
        'Connection': 'keep-alive',
        'Upgrade-Insecure-Requests': '1',
    }

    print(f"ğŸ” Debug de: {url}")
    print("=" * 60)

    try:
        response = requests.get(url, headers=headers, timeout=30)
        response.raise_for_status()

        print(f"âœ… Status: {response.status_code}")
        print(f"ğŸ“ Taille: {len(response.text)} caractÃ¨res")

        soup = BeautifulSoup(response.text, 'html.parser')

        # Chercher diffÃ©rents patterns d'offres
        print("\nğŸ” Recherche d'offres d'emploi...")

        # Pattern 1: Chercher les offres par titre
        titles = soup.find_all(['h1', 'h2', 'h3', 'h4'], string=lambda text: text and ('assistant' in text.lower() or 'gestionnaire' in text.lower() or 'commercia' in text.lower()))
        print(f"ğŸ“‹ Titres potentiels trouvÃ©s: {len(titles)}")
        for i, title in enumerate(titles[:3]):
            print(f"   {i+1}. {title.text.strip()}")

        # Pattern 2: Chercher les offres par structure
        offers = soup.find_all(['div', 'article'], class_=lambda c: c and any(word in str(c).lower() for word in ['offer', 'job', 'emploi', 'offre']))
        print(f"ğŸ“¦ Ã‰lÃ©ments avec classes 'offer/job/emploi': {len(offers)}")

        # Pattern 3: Chercher par contenu (Code:, Date d'Ã©dition:)
        code_elements = soup.find_all(string=lambda text: text and 'Code:' in text)
        print(f"ğŸ·ï¸  Ã‰lÃ©ments avec 'Code:': {len(code_elements)}")

        date_elements = soup.find_all(string=lambda text: text and "Date d'Ã©dition:" in text)
        print(f"ğŸ“… Ã‰lÃ©ments avec 'Date d'Ã©dition:': {len(date_elements)}")

        # Pattern 4: Chercher les numÃ©ros de code (format 137560)
        code_pattern = soup.find_all(string=lambda text: text and re.match(r'\d{6}', text.strip()))
        print(f"ğŸ”¢ NumÃ©ros Ã  6 chiffres: {len(code_pattern)}")

        # Analyser la structure gÃ©nÃ©rale
        print("\nğŸ—ï¸  Structure gÃ©nÃ©rale:")
        body = soup.find('body')
        if body:
            main_content = body.find(['main', 'div'], class_=lambda c: c and 'container' in str(c).lower())
            if main_content:
                print("   âœ… Conteneur principal trouvÃ©")
                job_sections = main_content.find_all(['div', 'section'], recursive=False)
                print(f"   ğŸ“‚ Sections dans le conteneur: {len(job_sections)}")
            else:
                print("   âŒ Pas de conteneur principal trouvÃ©")

        # Sauvegarder un extrait pour analyse
        print("\nğŸ’¾ Sauvegarde d'un extrait HTML...")
        with open('/tmp/educarriere_debug.html', 'w', encoding='utf-8') as f:
            # Sauvegarder juste le body ou les 2000 premiers caractÃ¨res
            content = str(body) if body else response.text[:2000]
            f.write(content)

        print("âœ… Extrait sauvegardÃ© dans /tmp/educarriere_debug.html")

        return True

    except Exception as e:
        print(f"âŒ Erreur: {e}")
        return False

if __name__ == '__main__':
    debug_educarriere()
