# ğŸ‡¨ğŸ‡® Scrapers CÃ´te d'Ivoire - Architecture

## Vue d'ensemble

Cette architecture de scraping a Ã©tÃ© adaptÃ©e au contexte ivoirien pour collecter des offres d'emploi depuis les principales plateformes locales.

## ğŸ“Š Sources de DonnÃ©es

| Scraper | Site | Volume EstimÃ© | ComplexitÃ© | Statut |
|---------|------|---------------|------------|--------|
| **educarriere** | `emploi.educarriere.ci` | **809 offres** | â­â­â­â­â­ Facile | âœ… ImplÃ©mentÃ© |
| **macarrierepro** | `macarrierepro.net` | **+300 offres** | â­â­â­â­ Moyenne | âœ… ImplÃ©mentÃ© |
| **emploi_ci** | `emploi.ci` | **500-1000 offres** | â­â­â­ Moyenne | âœ… ImplÃ©mentÃ© |
| **linkedin** | `linkedin.com` | **100-200 offres** | â­â­ Ã‰levÃ©e | âœ… ImplÃ©mentÃ© |

## ğŸ—ï¸ Architecture Technique

```
kafka/producers/
â”œâ”€â”€ scrapers/
â”‚   â”œâ”€â”€ base_scraper.py          # Classe abstraite commune
â”‚   â”œâ”€â”€ educarriere_scraper.py   # 809 offres - Parsing simple
â”‚   â”œâ”€â”€ macarrierepro_scraper.py # +300 offres - Interface moderne
â”‚   â”œâ”€â”€ emploi_ci_scraper.py     # Volume principal - Adaptable
â”‚   â””â”€â”€ linkedin_scraper.py      # DonnÃ©es premium - Selenium
â”œâ”€â”€ utils/
â”‚   â””â”€â”€ anti_ban.py             # Rotation User-Agent, proxies
â””â”€â”€ run_scraper.py              # Orchestrateur principal
```

## ğŸ”§ FonctionnalitÃ©s Communes

### BaseScraperCI (`base_scraper.py`)

**Anti-ban & Rate Limiting :**
- Rotation automatique des User-Agents
- DÃ©lais alÃ©atoires entre requÃªtes (2-5 secondes)
- Gestion des erreurs et retry logic

**Normalisation des DonnÃ©es :**
- **Localisation** : Standardisation des villes ivoiriennes (Abidjan, BouakÃ©, etc.)
- **Salaire** : Parsing des montants en FCFA avec pÃ©riodes (mois, annÃ©e)
- **CompÃ©tences** : Extraction automatique des skills techniques/mÃ©tier
- **ID unique** : GÃ©nÃ©ration dÃ©terministe des identifiants

**IntÃ©gration :**
- **Kafka** : Envoi structurÃ© vers `job-offers-raw`
- **MinIO** : Sauvegarde HTML dans `scraped-jobs/`
- **Logging** : Suivi dÃ©taillÃ© avec mÃ©triques

## ğŸ“‹ Scrapers SpÃ©cifiques

### 1. EducarriereScraper

**Source** : https://emploi.educarriere.ci/nos-offres
**Points forts** :
- **809 offres** actives
- Structure HTML trÃ¨s claire
- Pagination simple (29 pages)
- DonnÃ©es bien organisÃ©es (Code, Date, Type)

**DonnÃ©es extraites** :
- Code unique, titre, dates
- Type d'emploi (CDI, Stage, etc.)
- Description basique
- CompÃ©tences dÃ©duites du titre

### 2. MacarriereproScraper

**Source** : https://macarrierepro.net/
**Points forts** :
- **+300 offres** avec salaires affichÃ©s
- Interface moderne avec catÃ©gories
- DonnÃ©es enrichies (entreprise, salaire, localisation)

**DonnÃ©es extraites** :
- Titre, entreprise, localisation
- **Salaire en FCFA** (parsing avancÃ©)
- CompÃ©tences par catÃ©gorie
- Secteur d'activitÃ© et niveau d'expÃ©rience

### 3. EmploiCIScraper

**Source** : https://www.emploi.ci/
**Points forts** :
- Volume principal estimÃ© (500-1000 offres)
- Architecture adaptable Ã  diffÃ©rentes structures
- Extraction intelligente des compÃ©tences

**DonnÃ©es extraites** :
- Parsing flexible selon la structure du site
- DÃ©tection automatique des compÃ©tences
- Analyse sÃ©mantique du titre et description
- Classification secteur/industrie

### 4. LinkedInScraper â­ **Premium**

**Source** : https://www.linkedin.com/jobs/
**Points forts** :
- **DonnÃ©es premium** : profils dÃ©taillÃ©s, compÃ©tences validÃ©es
- **Authentification officielle** : accÃ¨s aux offres rÃ©servÃ©es
- **RÃ©seau professionnel** : donnÃ©es de qualitÃ© supÃ©rieure
- **Filtrage avancÃ©** : recherche ciblÃ©e CÃ´te d'Ivoire

**Configuration requise** :
```bash
# Copier le fichier d'exemple
cp config/linkedin_credentials.example kafka/producers/.env.linkedin

# Ã‰diter avec vos vraies credentials
nano kafka/producers/.env.linkedin
```

**Variables d'environnement** :
- `LINKEDIN_EMAIL` : Email LinkedIn
- `LINKEDIN_PASSWORD` : Mot de passe LinkedIn
- `SELENIUM_HEADLESS=true` : Mode headless (production)
- `LINKEDIN_ENRICH_DETAILS=false` : Enrichissement dÃ©tails (lent)

**DonnÃ©es extraites** :
- **CompÃ©tences validÃ©es** par LinkedIn
- **Profils entreprise complets**
- **Informations salariales** quand disponibles
- **Niveau d'expÃ©rience** et secteur
- **Options tÃ©lÃ©travail** explicites
- **Dates de publication prÃ©cises**

**âš ï¸ ConsidÃ©rations importantes** :
- **Rate limiting strict** : LinkedIn limite les connexions
- **Authentification requise** : Compte LinkedIn valide nÃ©cessaire
- **DÃ©lais anti-ban** : Attendre 2-3 secondes entre actions
- **IP rotation** recommandÃ©e pour usage intensif

## ğŸš€ Utilisation

### Lancement Individuel

```bash
# Test rapide (2 pages)
python kafka/producers/run_scraper.py --scraper educarriere --max-pages 2 --verbose

# Scraping complet
python kafka/producers/run_scraper.py --scraper macarrierepro --max-pages 10

# LinkedIn (nÃ©cessite credentials)
python kafka/producers/run_scraper.py --scraper linkedin --max-jobs 25
```

### Lancement Tous Scrapers

```bash
# Mode test (2 pages chacun)
python kafka/producers/run_scraper.py --scraper all --max-pages 2

# Production (pages illimitÃ©es)
python kafka/producers/run_scraper.py --scraper all
```

### Options Disponibles

```bash
--scraper {all,educarriere,macarrierepro,emploi_ci}  # Scraper Ã  lancer
--max-pages INT                                     # Pages max par scraper
--delay-min FLOAT                                   # DÃ©lai min entre requÃªtes
--delay-max FLOAT                                   # DÃ©lai max entre requÃªtes
--verbose                                           # Mode debug
```

## ğŸ“Š MÃ©triques et Monitoring

Chaque scraper fournit :
- **jobs_scraped** : Nombre d'offres collectÃ©es
- **jobs_sent_kafka** : Offres envoyÃ©es Ã  Kafka
- **jobs_saved_minio** : HTML sauvegardÃ© dans MinIO
- **errors** : Nombre d'erreurs
- **duration_seconds** : Temps d'exÃ©cution

## ğŸ”§ Configuration

### Variables d'Environnement

```bash
# Kafka
KAFKA_BOOTSTRAP_SERVERS=kafka:29092

# MinIO
MINIO_ENDPOINT=minio:9000

# Scraping gÃ©nÃ©ral
SCRAPER_DELAY_MIN=2.0
SCRAPER_DELAY_MAX=5.0

# LinkedIn (si utilisÃ©)
LINKEDIN_EMAIL=votre_email@linkedin.com
LINKEDIN_PASSWORD=votre_mot_de_passe
SELENIUM_HEADLESS=true
LINKEDIN_ENRICH_DETAILS=false
```

### Adaptation aux Sites

Pour ajouter un nouveau site ivoirien :

1. **CrÃ©er** `nouveau_scraper.py` hÃ©ritant de `BaseJobScraperCI`
2. **ImplÃ©menter** `scrape_page()` et `parse_jobs_from_html()`
3. **Ajouter** au dictionnaire dans `run_scraper.py`
4. **Tester** avec `--scraper nouveau --max-pages 2`

## ğŸ¯ Points d'AmÃ©lioration Futurs

### Performance
- **Multithreading** pour scraper plusieurs pages en parallÃ¨le
- **Cache intelligent** pour Ã©viter re-scraping
- **Proxy rotation** pour volumes Ã©levÃ©s

### DonnÃ©es
- **Enrichissement NLP** avec spaCy pour extraction compÃ©tences
- **GÃ©ocodage** des localisations pour cartes
- **DÃ©duplication** inter-sources

### Monitoring
- **Dashboard Grafana** pour mÃ©triques temps rÃ©el
- **Alertes automatiques** sur Ã©checs
- **Rapports quotidiens** d'activitÃ©

## ğŸ“ Support

**Test rapide** : Lancez toujours avec `--max-pages 2` pour valider
**Logs** : VÃ©rifiez `/app/logs/scrapers_orchestrator.log`
**Debug** : Utilisez `--verbose` pour dÃ©tails complets

### ğŸ”’ Bonnes Pratiques LinkedIn

**SÃ©curitÃ© du compte** :
- Utilisez un compte LinkedIn dÃ©diÃ© au scraping
- Activez la 2FA si possible
- Ã‰vitez de scraper pendant les heures de bureau
- Respectez les limites LinkedIn (max 100-200 offres/jour)

**Performance** :
- `SELENIUM_HEADLESS=true` en production
- Commencez par `LINKEDIN_ENRICH_DETAILS=false`
- Limitez Ã  25-50 offres par exÃ©cution
- Attendez 2-3 secondes entre les actions

**DÃ©pannage** :
- Si blocage IP : Utilisez un VPN ou proxy
- Si compte suspendu : CrÃ©ez un nouveau compte
- VÃ©rifiez les logs Selenium pour les erreurs

---

**Total estimÃ©** : **1800-2500 offres/jour** avec les 4 scrapers actifs ğŸ¯
