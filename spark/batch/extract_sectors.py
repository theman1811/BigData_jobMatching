#!/usr/bin/env python3
"""
==========================================
Spark Batch - Extract Sectors
==========================================
Job Spark Batch pour l'extraction et classification des secteurs d'activitÃ©.

Source: s3a://processed-data/jobs_parsed/
Destination: BigQuery (Dim_Secteur + mise Ã  jour Fact_OffresEmploi)

Algorithme:
- Analyse titre, entreprise, description
- Classification secteurs ivoiriens
- HiÃ©rarchie avec categorie_parent
- Enrichissement BigQuery
"""

import os
import sys
from datetime import datetime
from pyspark.sql import SparkSession
from pyspark.sql.functions import (
    col, udf, lower, trim, regexp_replace, concat_ws,
    when, coalesce, current_timestamp, date_format,
    lit, struct, explode, collect_list, array_distinct,
    row_number, desc, count, avg
)
from pyspark.sql.types import (
    StructType, StructField, StringType, IntegerType, FloatType,
    BooleanType, ArrayType
)
from pyspark.sql.window import Window

import re


def create_spark_session():
    """CrÃ©e la session Spark avec configuration BigQuery et GCS"""
    spark_master = os.getenv("SPARK_MASTER", "spark://spark-master:7077")
    # Le chemin des credentials dÃ©pend du contexte (Airflow driver vs Spark executor)
    gcp_credentials = os.getenv("GOOGLE_APPLICATION_CREDENTIALS", "/opt/spark/credentials/bq-service-account.json")
    
    return SparkSession.builder \
        .appName("SectorExtractor") \
        .master(spark_master) \
        .config("spark.sql.adaptive.enabled", "true") \
        .config("spark.sql.adaptive.coalescePartitions.enabled", "true") \
        .config("spark.hadoop.fs.gs.impl", "com.google.cloud.hadoop.fs.gcs.GoogleHadoopFileSystem") \
        .config("spark.hadoop.fs.AbstractFileSystem.gs.impl", "com.google.cloud.hadoop.fs.gcs.GoogleHadoopFS") \
        .config("spark.hadoop.google.cloud.auth.service.account.json.keyfile", "/opt/spark/credentials/bq-service-account.json") \
        .config("spark.hadoop.google.cloud.auth.service.account.enable", "true") \
        .config("spark.jars.packages",
                "com.google.cloud.spark:spark-bigquery-with-dependencies_2.12:0.32.2,"
                "com.google.cloud.bigdataoss:gcs-connector:hadoop3-2.2.5") \
        .getOrCreate()


def classify_sector_udf(title, company, description, location):
    """
    UDF pour classifier une offre dans un secteur d'activitÃ© ivoirien

    Retourne un struct avec:
    - secteur_id: ID unique du secteur
    - secteur_nom: Nom du secteur
    - categorie_parent: CatÃ©gorie parente
    - confidence: Score de confiance (0-1)
    """
    if not any([title, company, description]):
        return {
            "secteur_id": "SECT_INCONNU",
            "secteur_nom": "Secteur inconnu",
            "categorie_parent": "INCONNU",
            "confidence": 0.0
        }

    # Combiner tout le texte pour l'analyse
    full_text = " ".join(filter(None, [title, company, description, location]))
    full_text_lower = full_text.lower()

    # Catalogue des secteurs Ã©conomiques ivoiriens
    secteurs_ivoiriens = {
        # TECHNOLOGIES & NUMÃ‰RIQUE
        "SECT_TECH": {
            "nom": "Technologies & Informatique",
            "parent": "SERVICES_NUMERIQUES",
            "mots_cles": [
                "informatique", "dÃ©veloppeur", "dÃ©veloppement", "programmeur", "it", "digital",
                "web", "mobile", "application", "logiciel", "data", "analyste", "scientist",
                "intelligence artificielle", "ia", "machine learning", "big data", "cloud",
                "aws", "azure", "google cloud", "devops", "docker", "kubernetes", "cyber",
                "sÃ©curitÃ© informatique", "rÃ©seau", "systÃ¨me", "base de donnÃ©es", "sql",
                "python", "java", "javascript", "php", "react", "angular", "vue", ".net",
                "c#", "c++", "swift", "kotlin", "scala", "r", "spark", "hadoop", "kafka"
            ],
            "entreprises": [
                "orange", "mtn", "moov", "canal+", "nsia", "ecobank", "sgbci", "baci",
                "uba", "boa", "vsat", "africa systems", "business intelligence"
            ]
        },

        # TÃ‰LÃ‰COMMUNICATIONS
        "SECT_TELECOM": {
            "nom": "TÃ©lÃ©communications",
            "parent": "SERVICES_NUMERIQUES",
            "mots_cles": [
                "tÃ©lÃ©com", "tÃ©lÃ©phone", "mobile", "rÃ©seau", "4g", "5g", "fibre", "internet",
                "opÃ©rateur", "gsm", "vsat", "satellite", "communication", "data center",
                "cloud computing", "iot", "objets connectÃ©s", "smart city"
            ],
            "entreprises": [
                "orange", "mtn", "moov", "canal+", "africa systems", "cÃ´te d'ivoire telecom",
                "ivoire telecom", "telecel", "green", "yoomee", "nsia", "ecobank"
            ]
        },

        # BANQUE & FINANCE
        "SECT_FINANCE": {
            "nom": "Banque & Finance",
            "parent": "SERVICES_FINANCIERS",
            "mots_cles": [
                "banque", "banquier", "finance", "financier", "comptabilitÃ©", "comptable",
                "audit", "auditeur", "contrÃ´leur", "gestion", "budget", "trÃ©sorerie",
                "crÃ©dit", "prÃªt", "Ã©pargne", "assurance", "assureur", "actuaire",
                "risk management", "compliance", "reglementation", "banque centrale",
                "microfinance", "sfd", "institution financiÃ¨re", "bfc", "bci", "bicici"
            ],
            "entreprises": [
                "nsia", "ecobank", "sgbci", "baci", "boa", "bicici", "bfc", "uba",
                "banque Atlantique", "banque de l'habitat", "biic", "bnii", "bsic",
                "banque centrale", "bceao", "microcred", "fefi", "finadev"
            ]
        },

        # ASSURANCE
        "SECT_ASSURANCE": {
            "nom": "Assurance",
            "parent": "SERVICES_FINANCIERS",
            "mots_cles": [
                "assurance", "assureur", "courtier", "risque", "sinistre", "indemnisation",
                "actuaire", "souscription", "rÃ©assurance", "mutuelle", "prÃ©voyance",
                "santÃ©", "automobile", "habitation", "responsabilitÃ© civile"
            ],
            "entreprises": [
                "nsia assurance", "allianz", "axa", "generali", "atlantic assurance",
                "saar", "sun assurance", "agra", "sicore", "scac", "mutuelle"
            ]
        },

        # AGRO-INDUSTRIE
        "SECT_AGRO": {
            "nom": "Agro-industrie",
            "parent": "INDUSTRIE_AGRICOLE",
            "mots_cles": [
                "agriculture", "agricole", "cacao", "cafÃ©", "anacarde", "hÃ©vÃ©a", "coton",
                "palme", "huile", "sucre", "riz", "maÃ¯s", "banane", "ananas", "mangue",
                "transformation", "agro-alimentaire", "coopÃ©rative", "plantation",
                "irrigation", "semence", "engrais", "pesticide", "export", "filiale"
            ],
            "entreprises": [
                "sifca", "sapc", "cabc", "coris", "bnetd", "palmci", "sucaf",
                "ivoria", "olam", "cargill", "louis dreyfus", "socapalm", "bollore",
                "africa food", "chococam", "sicor", "coopÃ©rative", "plantation"
            ]
        },

        # BTP & CONSTRUCTION
        "SECT_BTP": {
            "nom": "BTP & Construction",
            "parent": "INDUSTRIE_CONSTRUCTION",
            "mots_cles": [
                "construction", "bÃ¢timent", "travaux publics", "tp", "btp", "architecte",
                "ingÃ©nieur", "chantier", "maÃ§on", "Ã©lectricien", "plombier", "peintre",
                "ciment", "bÃ©ton", "acier", "infrastructure", "route", "pont", "tunnel",
                "immeuble", "rÃ©sidentiel", "commercial", "projet", "urbanisme"
            ],
            "entreprises": [
                "bollore", "bouygues", "vinci", "eiffage", "razel", "somagec", "setraci",
                "poti", "scetia", "sogea", "dumez", "citra", "sogea-satamur", "icf",
                "cimaf", "ciments de la cÃ´te", "unibÃ©ton", "bÃ©ton cellulaire"
            ]
        },

        # COMMERCE & DISTRIBUTION
        "SECT_COMMERCE": {
            "nom": "Commerce & Distribution",
            "parent": "SERVICES_COMMERCIAUX",
            "mots_cles": [
                "commerce", "vente", "commercial", "distribution", "import", "export",
                "grossiste", "dÃ©taillant", "magasin", "boutique", "supermarchÃ©", "hypermarchÃ©",
                "franchise", "reprÃ©sentant", "agent commercial", "business development",
                "marketing", "promotion", "client", "relation client", "crm"
            ],
            "entreprises": [
                "bollore", "cfa", "carrefour", "supermarchÃ©", "pharmacie", "jumia",
                "kilimall", "yango market", "capri cavanni", "tcb", "sociÃ©tÃ© gÃ©nÃ©rale",
                "shell", "total", "ivoire Ã©nergie", "distribution", "import-export"
            ]
        },

        # SANTÃ‰ & PHARMACIE
        "SECT_SANTE": {
            "nom": "SantÃ© & Pharmacie",
            "parent": "SERVICES_SANTE",
            "mots_cles": [
                "mÃ©decin", "docteur", "infirmier", "pharmacien", "chirurgien", "hospitalier",
                "clinique", "hÃ´pital", "cabinet", "laboratoire", "analyse", "radiologie",
                "pharmacie", "mÃ©dicament", "soins", "santÃ© publique", "Ã©pidÃ©miologie",
                "vaccination", "maladie", "traitement", "diagnostic", "urgence"
            ],
            "entreprises": [
                "pharmacie", "clinique", "hÃ´pital", "polyclinique", "laboratoire",
                "bioanalyse", "radiologie", "pharmacie populaire", "sanofi", "pfizer",
                "gsk", "novartis", "msd", "roche", "bms", "jnj", "abbott"
            ]
        },

        # Ã‰DUCATION & FORMATION
        "SECT_EDUCATION": {
            "nom": "Ã‰ducation & Formation",
            "parent": "SERVICES_EDUCATION",
            "mots_cles": [
                "enseignant", "professeur", "Ã©ducation", "Ã©cole", "universitÃ©", "formation",
                "pÃ©dagogie", "didactique", "apprentissage", "stage", "alternance",
                "enseignement supÃ©rieur", "secondaire", "primaire", "maternelle",
                "langue", "mathÃ©matiques", "sciences", "lettres", "histoire", "gÃ©ographie"
            ],
            "entreprises": [
                "universitÃ©", "inphb", "esp", "ens", "institut", "Ã©cole", "lycÃ©e",
                "collÃ¨ge", "maternelle", "centre de formation", "orange digital center",
                "microsoft innovation center", "google", "ibm", "cfa", "afdb"
            ]
        },

        # ADMINISTRATION PUBLIQUE
        "SECT_ADMIN": {
            "nom": "Administration Publique",
            "parent": "SERVICES_PUBLICS",
            "mots_cles": [
                "administration", "fonction publique", "ministÃ¨re", "secrÃ©tariat", "d'Ã©tat",
                "prÃ©fet", "sous-prÃ©fet", "mairie", "commune", "collectivitÃ©", "territoriale",
                "service public", "Ã©tat", "gouvernement", "ambassade", "consulat",
                "police", "gendarmerie", "armÃ©e", "dÃ©fense", "justice", "tribunal"
            ],
            "entreprises": [
                "Ã©tat", "gouvernement", "prÃ©sidence", "primature", "ministÃ¨re", "dgi",
                "dgf", "douane", "police", "gendarmerie", "armÃ©e", "justice", "tribunal",
                "cour", "ambassade", "consulat", "onu", "pnud", "fao", "afdb"
            ]
        },

        # HÃ”TELLERIE & TOURISME
        "SECT_HOTELLERIE": {
            "nom": "HÃ´tellerie & Tourisme",
            "parent": "SERVICES_TOURISTIQUES",
            "mots_cles": [
                "hÃ´tel", "hÃ´telier", "restaurant", "tourisme", "touriste", "guide",
                "agence de voyage", "rÃ©ceptif", "loisir", "Ã©vÃ©nement", "congrÃ¨s",
                "sÃ©minaire", "mariage", "cÃ©rÃ©monie", "traiteur", "cuisine", "chef"
            ],
            "entreprises": [
                "novotel", "ibis", "radisson", "azalai", "tropico", "sofitel", "hilton",
                "marriott", "accor", "restaurant", "agence de voyage", "discovery",
                "visit cÃ´te d'ivoire", "office du tourisme", "congress center"
            ]
        },

        # TRANSPORT & LOGISTIQUE
        "SECT_TRANSPORT": {
            "nom": "Transport & Logistique",
            "parent": "SERVICES_TRANSPORT",
            "mots_cles": [
                "transport", "logistique", "livreur", "chauffeur", "camion", "vÃ©hicule",
                "aÃ©roport", "avion", "pilote", "steward", "cargo", "port", "dock",
                "transit", "supply chain", "entreposage", "warehouse", "distribution"
            ],
            "entreprises": [
                "bollore", "sdv", "maersk", "cma cgm", "air cÃ´te d'ivoire", "air france",
                "ethiopian", "turkish airlines", "brussels airlines", "port autonome",
                "sag", "setrag", "utc", "sociÃ©tÃ© de transport", "dhl", "ups", "fedex"
            ]
        },

        # Ã‰NERGIE & MINES
        "SECT_ENERGIE": {
            "nom": "Ã‰nergie & Mines",
            "parent": "INDUSTRIE_ENERGIE",
            "mots_cles": [
                "Ã©nergie", "electricitÃ©", "cie", "hydrocarbure", "pÃ©trole", "gaz",
                "mine", "exploitation", "gÃ©ologue", "forage", "sismique", "pipeline",
                "raffinerie", "distribution", "Ã©olien", "solaire", "renouvelable"
            ],
            "entreprises": [
                "cie", "petroci", "total", "shell", "esso", "ivoire Ã©nergie", "aip",
                "geoci", "sodemi", "sociÃ©tÃ© miniÃ¨re", "endiama", "china minmetals"
            ]
        },

        # INDUSTRIE MANUFACTURIÃˆRE
        "SECT_MANUFACTURE": {
            "nom": "Industrie ManufacturiÃ¨re",
            "parent": "INDUSTRIE_MANUFACTURE",
            "mots_cles": [
                "industrie", "manufacture", "usine", "production", "qualitÃ©", "process",
                "maintenance", "ingÃ©nieur", "technicien", "opÃ©rateur", "ligne production",
                "emballage", "conditionnement", "supply chain", "lean", "six sigma"
            ],
            "entreprises": [
                "bollore", "sifca", "unilever", "nestle", "p&g", "coca cola", "pepsi",
                "sabc", "palmci", "cimaf", "bÃ©ton cellulaire", "plastic industry"
            ]
        }
    }

    # Recherche du secteur le plus probable
    best_match = {
        "secteur_id": "SECT_INCONNU",
        "secteur_nom": "Secteur inconnu",
        "categorie_parent": "INCONNU",
        "confidence": 0.0
    }

    for secteur_id, secteur_info in secteurs_ivoiriens.items():
        confidence = 0.0
        matches = 0

        # Recherche dans les mots-clÃ©s
        for mot_cle in secteur_info["mots_cles"]:
            if mot_cle in full_text_lower:
                matches += 1

        if matches > 0:
            confidence += min(matches * 0.3, 0.8)  # Max 0.8 pour mots-clÃ©s

        # Recherche dans les entreprises
        for entreprise in secteur_info["entreprises"]:
            if entreprise.lower() in full_text_lower:
                confidence += 0.5  # Bonus fort pour entreprise connue
                break

        # Bonus pour mots dans le titre (plus important)
        title_lower = (title or "").lower()
        for mot_cle in secteur_info["mots_cles"]:
            if mot_cle in title_lower:
                confidence += 0.2

        # Si meilleure confiance trouvÃ©e
        if confidence > best_match["confidence"]:
            best_match = {
                "secteur_id": secteur_id,
                "secteur_nom": secteur_info["nom"],
                "categorie_parent": secteur_info["parent"],
                "confidence": min(confidence, 1.0)
            }

    return best_match




def process_sector_extraction(spark, input_path, bigquery_dataset, gcp_project_id):
    """
    Traite l'extraction et classification des secteurs

    Args:
        spark: SparkSession
        input_path: Chemin MinIO source
        bigquery_dataset: Dataset BigQuery
        gcp_project_id: Projet GCP
    """

    # Enregistrer les UDFs
    classify_sector = udf(classify_sector_udf,
                         StructType([
                             StructField("secteur_id", StringType()),
                             StructField("secteur_nom", StringType()),
                             StructField("categorie_parent", StringType()),
                             StructField("confidence", FloatType())
                         ]))

    print("âœ… UDFs enregistrÃ©es")

    # Lire les donnÃ©es parsÃ©es
    jobs_df = spark.read.parquet(input_path)
    total_jobs = jobs_df.count()

    print(f"âœ… {total_jobs} offres lues depuis {input_path}")

    # Ã‰tape 1: Classification des secteurs
    classified_df = jobs_df \
        .withColumn("sector_classification",
                   classify_sector(col("title"), col("company"), col("description"), col("location"))) \
        .withColumn("secteur_id", col("sector_classification.secteur_id")) \
        .withColumn("secteur_nom", col("sector_classification.secteur_nom")) \
        .withColumn("categorie_parent", col("sector_classification.categorie_parent")) \
        .withColumn("sector_confidence", col("sector_classification.confidence"))

    print("âœ… Classification sectorielle effectuÃ©e")

    # Ã‰tape 2: Statistiques des classifications
    sector_stats = classified_df \
        .groupBy("secteur_id", "secteur_nom", "categorie_parent") \
        .agg(
            count("*").alias("offres_count"),
            (avg("sector_confidence") * 100).alias("avg_confidence_pct")
        ) \
        .orderBy(desc("offres_count"))

    print("ğŸ“Š RÃ©partition par secteur:")
    sector_stats.show(20, False)

    # Ã‰tape 3: PrÃ©parer les donnÃ©es pour Dim_Secteur
    dim_secteur_df = classified_df \
        .select("secteur_id", "secteur_nom", "categorie_parent") \
        .distinct() \
        .withColumn("description",
                   when(col("secteur_id") == "SECT_INCONNU", "Secteur non classifiÃ©")
                   .otherwise(concat_ws(" - ", col("secteur_nom"), col("categorie_parent")))) \
        .withColumn("created_at", current_timestamp()) \
        .filter(col("secteur_id").isNotNull()) \
        .dropDuplicates(["secteur_id"])

    print(f"âœ… {dim_secteur_df.count()} secteurs uniques identifiÃ©s")

    # Ã‰tape 4: Charger Dim_Secteur dans BigQuery (optionnel, non bloquant)
    bq_options = {
        "project": gcp_project_id,
        "dataset": bigquery_dataset,
        "temporaryGcsBucket": f"{gcp_project_id}-temp-spark-bq"
    }

    bq_success = False
    try:
        secteur_table = f"{bigquery_dataset}.Dim_Secteur"

        dim_secteur_df.write \
            .format("bigquery") \
            .option("table", secteur_table) \
            .options(**bq_options) \
            .mode("append") \
            .save()

        print(f"âœ… Dim_Secteur chargÃ©e dans BigQuery ({dim_secteur_df.count()} secteurs)")
        bq_success = True

    except Exception as e:
        print(f"âš ï¸  Erreur chargement Dim_Secteur dans BigQuery (non bloquant): {e}")
        print("   â†’ Continuation avec sauvegarde MinIO uniquement")
        bq_success = False

    # Ã‰tape 5: PrÃ©parer les donnÃ©es finales avec vrais secteur_id
    enriched_jobs_df = classified_df \
        .withColumn("source", coalesce(col("source"), lit("unknown"))) \
        .select(
            col("job_id"),
            col("source"),
            col("title"),
            col("company"),
            col("description"),
            col("requirements"),
            col("location"),
            col("parsed_salary_text"),
            col("contract_type"),
            col("skills"),
            col("parsed_at"),
            col("parsing_quality_score"),
            col("secteur_id"),
            col("secteur_nom"),
            col("categorie_parent"),
            col("sector_confidence"),
            current_timestamp().alias("sector_processed_at")
        )

    # Sauvegarder les donnÃ©es enrichies dans MinIO
    output_path = f"s3a://processed-data/jobs_enriched_sectors"
    enriched_jobs_df.write \
        .mode("overwrite") \
        .partitionBy("source") \
        .parquet(output_path)

    print(f"âœ… DonnÃ©es enrichies sauvegardÃ©es vers {output_path}")

    # Statistiques finales
    final_stats = enriched_jobs_df \
        .select(
            count(when(col("secteur_id") != "SECT_INCONNU", 1)).alias("classified_jobs"),
            (avg("sector_confidence") * 100).alias("avg_confidence_pct"),
            count(when(col("sector_confidence") > 0.7, 1)).alias("high_confidence_jobs")
        ).collect()[0]

    classified_count = final_stats["classified_jobs"]
    avg_confidence = final_stats["avg_confidence_pct"]
    high_confidence_count = final_stats["high_confidence_jobs"]

    print("ğŸ“Š Statistiques finales:")
    print(f"   Offres classifiÃ©es: {classified_count}/{total_jobs}")
    print(".1f")
    print(f"   Haute confiance (>70%): {high_confidence_count}")

    return {
        "total_jobs": total_jobs,
        "classified_jobs": classified_count,
        "classification_rate": (classified_count / total_jobs) * 100 if total_jobs > 0 else 0,
        "avg_confidence": avg_confidence,
        "high_confidence_jobs": high_confidence_count,
        "dim_secteur_count": dim_secteur_df.count(),
        "bigquery_success": bq_success,
        "status": "SUCCESS"
    }


def main():
    """Fonction principale"""
    print("ğŸš€ DÃ©marrage de l'extraction des secteurs - Spark Batch")

    # Configuration
    input_bucket = os.getenv("MINIO_BUCKET", "processed-data")
    gcp_project_id = os.getenv("GCP_PROJECT_ID", "noble-anvil-479619-h9")
    bigquery_dataset = os.getenv("BIGQUERY_DATASET", "jobmatching_dw")

    input_path = f"s3a://{input_bucket}/jobs_parsed"

    print(f"ğŸ“‹ Configuration:")
    print(f"   Input: {input_path}")
    print(f"   GCP Project: {gcp_project_id}")
    print(f"   BigQuery Dataset: {bigquery_dataset}")

    try:
        # CrÃ©er la session Spark
        spark = create_spark_session()
        print("âœ… Session Spark crÃ©Ã©e")

        # Traiter l'extraction des secteurs
        result = process_sector_extraction(spark, input_path, bigquery_dataset, gcp_project_id)

        if result["status"] == "SUCCESS":
            print("âœ… Extraction des secteurs terminÃ©e avec succÃ¨s")
            print("ğŸ“Š Statistiques:")
            for key, value in result.items():
                if key != "status":
                    print(f"   {key}: {value}")
        else:
            print(f"âŒ Ã‰chec de l'extraction: {result.get('error', 'Erreur inconnue')}")
            sys.exit(1)

    except Exception as e:
        print(f"âŒ Erreur: {e}")
        import traceback
        traceback.print_exc()
        sys.exit(1)
    finally:
        if 'spark' in locals():
            spark.stop()
            print("âœ… Session Spark arrÃªtÃ©e")


if __name__ == "__main__":
    main()
