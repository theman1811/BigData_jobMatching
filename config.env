# Configuration Environnement - Big Data Project

# ==============================================
# CONFIGURATION GÉNÉRALE
# ==============================================
PROJECT_NAME=bigdata_orangescrum
COMPOSE_PROJECT_NAME=bigdata_orangescrum

# ==============================================
# AIRFLOW
# ==============================================
AIRFLOW_UID=50000
AIRFLOW_IMAGE_NAME=apache/airflow:2.8.0-python3.11
AIRFLOW_ADMIN_USER=airflow
AIRFLOW_ADMIN_PASSWORD=airflow
AIRFLOW_ADMIN_EMAIL=admin@example.com

# ==============================================
# SPARK
# ==============================================
SPARK_VERSION=3.5.0
SPARK_MASTER_PORT=7077
SPARK_MASTER_WEBUI_PORT=8081
SPARK_WORKER_CORES=2
SPARK_WORKER_MEMORY=2g

# ==============================================
# KAFKA
# ==============================================
KAFKA_VERSION=7.5.0
KAFKA_BROKER_ID=1
KAFKA_AUTO_CREATE_TOPICS=true

# ==============================================
# JUPYTER
# ==============================================
JUPYTER_TOKEN=bigdata2024
JUPYTER_PORT=8888

# ==============================================
# POSTGRESQL (pour Airflow)
# ==============================================
POSTGRES_USER=airflow
POSTGRES_PASSWORD=airflow
POSTGRES_DB=airflow

# ==============================================
# GCP (à configurer plus tard)
# ==============================================
GCP_PROJECT_ID=noble-anvil-479619-h9
GCP_PROJECT_NUMBER=613379523938
GCP_REGION=europe-west1
GCS_BUCKET_NAME=jobmatching-datalake
BIGQUERY_DATASET=jobmatching_dw
# Ajouter cette ligne dans config.env :
GOOGLE_APPLICATION_CREDENTIALS=./credentials/gcp-service-account.json


# Configuration WIF
WORKLOAD_IDENTITY_POOL=bigdata-workload-pool
WORKLOAD_IDENTITY_PROVIDER=local-dev-provider
WORKLOAD_IDENTITY_SERVICE_ACCOUNT=bigdata-sa@noble-anvil-479619-h9.iam.gserviceaccount.com

# ==============================================
# LINKEDIN SCRAPER (optionnel)
# ==============================================
# À décommenter et configurer si vous voulez utiliser le scraper LinkedIn
# LINKEDIN_EMAIL=votre_email_linkedin@exemple.com
# LINKEDIN_PASSWORD=votre_mot_de_passe_linkedin
# SELENIUM_HEADLESS=true
# LINKEDIN_ENRICH_DETAILS=false
# LINKEDIN_MAX_JOBS_PER_RUN=50

