# ğŸ—ï¸ Architecture DÃ©taillÃ©e - BigData OrangeScrum

## Vue d'ensemble

Ce document dÃ©crit l'architecture complÃ¨te de la plateforme Big Data mise en place pour le projet OrangeScrum.

## ğŸ¯ Objectifs

- **Ingestion** : Collecter des Ã©vÃ©nements en temps rÃ©el via Kafka
- **Stockage** : Stocker les donnÃ©es brutes dans un Data Lake (GCS) et structurÃ©es dans un Data Warehouse (BigQuery)
- **Traitement** : Transformer les donnÃ©es avec Apache Spark (batch et streaming)
- **Orchestration** : Automatiser les pipelines avec Apache Airflow
- **Visualisation** : CrÃ©er des dashboards BI avec Looker Studio

## ğŸ“ Architecture Technique

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    SOURCES DE DONNÃ‰ES                        â”‚
â”‚  (Applications, APIs, Fichiers, Bases de donnÃ©es, etc.)     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                       â”‚
                       â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                  COUCHE D'INGESTION (Local)                  â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚
â”‚  â”‚   KAFKA      â”‚  â”‚ SCHEMA REGISTRY â”‚  â”‚ KAFKA CONNECT  â”‚ â”‚
â”‚  â”‚ (Streaming)  â”‚  â”‚  (Validation)   â”‚  â”‚  (Connecteurs) â”‚ â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                       â”‚
                       â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚               COUCHE DE TRAITEMENT (Local)                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚
â”‚  â”‚              APACHE SPARK CLUSTER                      â”‚ â”‚
â”‚  â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”            â”‚ â”‚
â”‚  â”‚  â”‚  Master  â”‚  â”‚ Worker 1 â”‚  â”‚ Worker 2 â”‚            â”‚ â”‚
â”‚  â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜            â”‚ â”‚
â”‚  â”‚                                                        â”‚ â”‚
â”‚  â”‚  â€¢ Spark Streaming (Temps rÃ©el)                       â”‚ â”‚
â”‚  â”‚  â€¢ Spark Batch (Traitements lourds)                   â”‚ â”‚
â”‚  â”‚  â€¢ PySpark (Transformations)                          â”‚ â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                       â”‚
                       â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                COUCHE DE STOCKAGE (GCP)                      â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚  â”‚   DATA LAKE (GCS)    â”‚    â”‚  DATA WAREHOUSE          â”‚  â”‚
â”‚  â”‚                      â”‚    â”‚  (BIGQUERY)              â”‚  â”‚
â”‚  â”‚  â€¢ DonnÃ©es brutes    â”‚â”€â”€â”€â–¶â”‚                          â”‚  â”‚
â”‚  â”‚  â€¢ Parquet/Avro      â”‚    â”‚  â€¢ DonnÃ©es structurÃ©es   â”‚  â”‚
â”‚  â”‚  â€¢ PartitionnÃ©es     â”‚    â”‚  â€¢ ModÃ¨les BI            â”‚  â”‚
â”‚  â”‚  â€¢ 5 GB (Free Tier)  â”‚    â”‚  â€¢ AgrÃ©gations           â”‚  â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                       â”‚
                       â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                COUCHE DE VISUALISATION                       â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚
â”‚  â”‚              LOOKER STUDIO (Gratuit)                   â”‚ â”‚
â”‚  â”‚                                                        â”‚ â”‚
â”‚  â”‚  â€¢ Dashboards interactifs                             â”‚ â”‚
â”‚  â”‚  â€¢ Connexion directe Ã  BigQuery                       â”‚ â”‚
â”‚  â”‚  â€¢ Rapports planifiÃ©s                                 â”‚ â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚              COUCHE D'ORCHESTRATION (Local)                  â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚
â”‚  â”‚                 APACHE AIRFLOW                         â”‚ â”‚
â”‚  â”‚                                                        â”‚ â”‚
â”‚  â”‚  â€¢ Planification des jobs                             â”‚ â”‚
â”‚  â”‚  â€¢ Gestion des dÃ©pendances                            â”‚ â”‚
â”‚  â”‚  â€¢ Monitoring des pipelines                           â”‚ â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

## ğŸ”§ Composants DÃ©taillÃ©s

### 1. Ingestion (Apache Kafka)

**RÃ´le** : Recevoir et distribuer les Ã©vÃ©nements en temps rÃ©el

**Composants** :
- **Zookeeper** : Coordination du cluster Kafka
- **Kafka Broker** : Gestion des messages
- **Schema Registry** : Validation des schÃ©mas de donnÃ©es (Avro)
- **Kafka UI** : Interface de monitoring

**Configuration** :
- Port Kafka : 9092
- Port Schema Registry : 8081
- Port Kafka UI : 8080
- Topics auto-crÃ©Ã©s : activÃ©
- Retention : 7 jours

### 2. Traitement (Apache Spark)

**RÃ´le** : Transformer et enrichir les donnÃ©es

**Composants** :
- **Spark Master** : Gestionnaire du cluster (port 7077)
- **Spark Worker 1 & 2** : NÅ“uds de calcul (2 cores, 2GB chacun)

**CapacitÃ©s** :
- Spark Streaming : Traitement temps rÃ©el depuis Kafka
- Spark Batch : Traitements lourds planifiÃ©s
- PySpark : API Python pour les transformations

**Web UI** :
- Master : http://localhost:8082
- Worker 1 : http://localhost:8083
- Worker 2 : http://localhost:8084

### 3. Stockage (Google Cloud)

#### Data Lake (Google Cloud Storage)

**RÃ´le** : Stockage brut et Ã©conomique des donnÃ©es

**CaractÃ©ristiques** :
- Format : Parquet (compression optimale)
- Organisation : Partitionnement par date
- CoÃ»t : 0â‚¬ (Free Tier 5 GB)

**Structure** :
```
gs://orangescrum-datalake/
â”œâ”€â”€ raw/                    # DonnÃ©es brutes
â”‚   â”œâ”€â”€ events/
â”‚   â”‚   â””â”€â”€ date=2024-01-01/
â”‚   â”œâ”€â”€ logs/
â”‚   â””â”€â”€ metrics/
â”œâ”€â”€ processed/              # DonnÃ©es traitÃ©es
â”‚   â””â”€â”€ date=2024-01-01/
â””â”€â”€ archive/                # Archives
```

#### Data Warehouse (BigQuery)

**RÃ´le** : RequÃªtes analytiques rapides

**CaractÃ©ristiques** :
- Dataset : orangescrum_dw
- Tables partitionnÃ©es par date
- Clustering sur colonnes frÃ©quentes
- CoÃ»t : 0â‚¬ (Free Tier : 10 GB storage + 1 TB queries/mois)

**SchÃ©ma** :
```
orangescrum_dw/
â”œâ”€â”€ raw_events              # Table brute
â”œâ”€â”€ dim_users               # Dimension utilisateurs
â”œâ”€â”€ dim_projects            # Dimension projets
â”œâ”€â”€ fact_activities         # Fait activitÃ©s
â””â”€â”€ agg_daily_metrics       # AgrÃ©gations quotidiennes
```

### 4. Orchestration (Apache Airflow)

**RÃ´le** : Automatiser et planifier les pipelines

**Composants** :
- **Webserver** : Interface Web (port 8085)
- **Scheduler** : Planificateur de tÃ¢ches
- **PostgreSQL** : Base de donnÃ©es mÃ©tadonnÃ©es

**Credentials** :
- URL : http://localhost:8085
- Username : airflow
- Password : airflow

**DAGs types** :
1. **Ingestion quotidienne** : Charger donnÃ©es vers GCS
2. **Transformation batch** : Jobs Spark planifiÃ©s
3. **Chargement BigQuery** : Import depuis GCS
4. **Maintenance** : Nettoyage et archivage

### 5. DÃ©veloppement (Jupyter)

**RÃ´le** : DÃ©veloppement interactif PySpark

**AccÃ¨s** :
- URL : http://localhost:8888
- Token : bigdata2024

**Packages installÃ©s** :
- PySpark 3.5.0
- Kafka clients
- Google Cloud SDK
- Pandas, NumPy, Matplotlib

## ğŸ”„ Flux de DonnÃ©es

### Pipeline Temps RÃ©el (Streaming)

```
1. Source â†’ 2. Kafka â†’ 3. Spark Streaming â†’ 4. GCS â†’ 5. BigQuery â†’ 6. Looker Studio
   (App)    (Topic)     (Transformation)      (Raw)   (Warehouse)    (Dashboard)
```

**Exemple : Ã‰vÃ©nements utilisateurs**
```python
1. Application gÃ©nÃ¨re Ã©vÃ©nement â†’ events-raw
2. Spark Streaming consomme events-raw
3. Transformation et enrichissement
4. Ã‰criture dans GCS (Parquet)
5. Chargement dans BigQuery (batch 15 min)
6. Dashboard se met Ã  jour
```

### Pipeline Batch (PlanifiÃ©)

```
1. Airflow â†’ 2. Spark Batch â†’ 3. GCS â†’ 4. BigQuery â†’ 5. Looker Studio
   (DAG)       (Job)           (Parquet) (Table)       (Rapport)
```

**Exemple : AgrÃ©gations quotidiennes**
```python
1. Airflow DAG se dÃ©clenche Ã  2h du matin
2. Spark lit donnÃ©es de la veille depuis GCS
3. Calcule mÃ©triques agrÃ©gÃ©es
4. Ã‰crit rÃ©sultats dans BigQuery
5. Email de confirmation envoyÃ©
```

## ğŸ’¾ StratÃ©gie de DonnÃ©es

### ModÃ©lisation

**Approche** : ModÃ¨le en Ã©toile (Star Schema)

```
        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
        â”‚  dim_users   â”‚
        â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜
               â”‚
        â”Œâ”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
        â”‚                        â”‚
  â”Œâ”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”      â”Œâ”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”
  â”‚ dim_projects â”‚â—€â”€â”€â”€â”€â”€â”¤ fact_activitiesâ”‚
  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜      â””â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                â”‚
                        â”Œâ”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”
                        â”‚   dim_dates    â”‚
                        â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Partitionnement

**GCS** : Partitionnement par date (Hive style)
```
/data/events/year=2024/month=01/day=15/
```

**BigQuery** : Partitionnement sur colonne date
```sql
CREATE TABLE events
PARTITION BY DATE(event_timestamp)
CLUSTER BY user_id, event_type
```

### Formats de DonnÃ©es

| Couche | Format | Raison |
|--------|--------|--------|
| Ingestion | Avro | SchÃ©ma intÃ©grÃ©, Ã©volution |
| Lake (Raw) | Parquet | Compression, columnar |
| Lake (Processed) | Parquet | Performance, taille |
| Warehouse | BigQuery native | OptimisÃ© pour requÃªtes |

## ğŸ” SÃ©curitÃ©

### Authentification

- **Airflow** : Basic Auth (user/password)
- **GCP** : Service Account avec clÃ© JSON
- **Kafka** : PLAINTEXT (local), SSL en production

### Autorisation

**BigQuery** :
- Service Account avec rÃ´le minimal (BigQuery Data Editor)
- Row-level security sur tables sensibles

**GCS** :
- Bucket privÃ© (pas d'accÃ¨s public)
- IAM roles spÃ©cifiques par service

### Secrets Management

**Local** : Variables d'environnement (.env)
**Production** : Google Secret Manager

## ğŸ“Š Monitoring

### MÃ©triques Ã  Surveiller

1. **Kafka** :
   - Lag des consumers
   - Throughput (messages/sec)
   - Taille des partitions

2. **Spark** :
   - DurÃ©e des jobs
   - MÃ©moire utilisÃ©e
   - Tasks Ã©chouÃ©es

3. **Airflow** :
   - DAGs en Ã©chec
   - DurÃ©e d'exÃ©cution
   - SLA respectÃ©s

4. **GCP** :
   - CoÃ»ts quotidiens
   - Quotas utilisÃ©s
   - RequÃªtes BigQuery

### Outils de Monitoring

- **Kafka UI** : Monitoring Kafka
- **Spark Web UI** : Jobs en cours
- **Airflow UI** : Ã‰tat des DAGs
- **GCP Console** : Facturation et quotas

## ğŸš€ Ã‰volutions Futures

### Phase 2 (Optionnel)

1. **Data Quality** : IntÃ©gration de Great Expectations
2. **Data Catalog** : Ajout de DataHub ou Dataplex
3. **ML** : ModÃ¨les dans BigQuery ML
4. **Streaming avancÃ©** : Pub/Sub + Dataflow

### ScalabilitÃ©

**Si volumes augmentent** :
- Passer Ã  Dataproc pour Spark (auto-scaling)
- Utiliser Pub/Sub au lieu de Kafka local
- Activer crÃ©dits GCP Ã©tudiants (300$)

## ğŸ“š RÃ©fÃ©rences

- [Kafka Documentation](https://kafka.apache.org/documentation/)
- [Spark Documentation](https://spark.apache.org/docs/latest/)
- [Airflow Documentation](https://airflow.apache.org/docs/)
- [BigQuery Best Practices](https://cloud.google.com/bigquery/docs/best-practices)
- [Looker Studio Documentation](https://support.google.com/looker-studio)

