# ‚òÅÔ∏è Guide de Configuration GCP

Ce guide vous accompagne dans la configuration de votre compte Google Cloud Platform pour le projet BigData OrangeScrum.

## üéì √âtape 1 : Obtenir les Cr√©dits √âtudiants

### Programme Google Cloud for Education

1. **Acc√©der au programme √©tudiant** :
   - URL : https://cloud.google.com/edu
   - Ou : https://edu.google.com/programs/credits/

2. **V√©rifier votre √©ligibilit√©** :
   - Adresse email universitaire (@*.edu ou email √©tudiant)
   - Inscription dans un √©tablissement reconnu

3. **Cr√©er votre compte** :
   - Si vous avez d√©j√† un compte Google, utilisez-le
   - Sinon, cr√©ez un nouveau compte Gmail

4. **Obtenir les cr√©dits** :
   - **Option 1** : 300$ de cr√©dits gratuits (nouveau compte GCP)
     - Valable 90 jours
     - Aucune carte bancaire requise (version √©tudiante)
   
   - **Option 2** : Programme √©ducatif sp√©cifique
     - Varie selon l'√©tablissement
     - Demander √† votre professeur s'il existe un programme

## üöÄ √âtape 2 : Cr√©er un Projet GCP

### 2.1 Acc√©der √† la Console GCP

1. Se connecter √† : https://console.cloud.google.com
2. Accepter les conditions d'utilisation

### 2.2 Cr√©er un Nouveau Projet

1. Cliquer sur le s√©lecteur de projet (en haut)
2. Cliquer sur "Nouveau projet"
3. Remplir les informations :
   ```
   Nom du projet : bigdata-orangescrum
   ID du projet : bigdata-orangescrum-[random]
   Organisation : Aucune organisation
   ```
4. Cliquer sur "Cr√©er"

### 2.3 Activer la Facturation (si n√©cessaire)

1. Menu ‚â° ‚Üí "Facturation"
2. Lier le projet √† votre compte de facturation
3. Avec les cr√©dits √©tudiants, aucun paiement ne sera effectu√©

## üîë √âtape 3 : Cr√©er un Service Account

### 3.1 Pourquoi un Service Account ?

Le Service Account permet √† vos applications locales (Spark, Airflow) de s'authentifier sur GCP.

### 3.2 Cr√©ation

1. **Acc√©der √† IAM** :
   - Menu ‚â° ‚Üí "IAM et administration" ‚Üí "Comptes de service"

2. **Cr√©er le Service Account** :
   - Cliquer sur "+ CR√âER UN COMPTE DE SERVICE"
   - Nom : `bigdata-orangescrum-sa`
   - Description : `Service account pour le projet BigData`
   - Cliquer sur "Cr√©er et continuer"

3. **Attribuer les r√¥les** :
   - Ajouter les r√¥les suivants :
     ```
     ‚Ä¢ Storage Admin (pour GCS)
     ‚Ä¢ BigQuery Admin (pour BigQuery)
     ‚Ä¢ BigQuery Data Editor (pour √©crire des donn√©es)
     ‚Ä¢ BigQuery Job User (pour lancer des queries)
     ```
   - Cliquer sur "Continuer"

4. **Finaliser** :
   - Cliquer sur "Termin√©"

### 3.3 T√©l√©charger la Cl√© JSON

1. Dans la liste des comptes de service, trouver `bigdata-orangescrum-sa`
2. Cliquer sur les trois points ‚Üí "G√©rer les cl√©s"
3. "Ajouter une cl√©" ‚Üí "Cr√©er une cl√©"
4. Type : JSON
5. Cliquer sur "Cr√©er"
6. La cl√© se t√©l√©charge automatiquement

‚ö†Ô∏è **IMPORTANT** : Cette cl√© donne acc√®s √† votre projet. Ne la commitez JAMAIS dans Git !

### 3.4 Configurer la Cl√© Localement

```bash
# Cr√©er un dossier pour les credentials
cd /Users/apple/Documents/programmation/school/bigData_orangeScrum
mkdir -p credentials

# D√©placer la cl√© t√©l√©charg√©e
mv ~/Downloads/bigdata-orangescrum-*.json credentials/gcp-service-account.json

# V√©rifier
ls credentials/
```

## ü™£ √âtape 4 : Cr√©er un Bucket GCS (Data Lake)

### 4.1 Activer l'API Cloud Storage

1. Menu ‚â° ‚Üí "APIs et services" ‚Üí "Biblioth√®que"
2. Rechercher "Cloud Storage"
3. Cliquer sur "Cloud Storage API"
4. Cliquer sur "Activer"

### 4.2 Cr√©er le Bucket

1. **Via la Console** :
   - Menu ‚â° ‚Üí "Cloud Storage" ‚Üí "Buckets"
   - Cliquer sur "+ CR√âER"
   - Configuration :
     ```
     Nom : orangescrum-datalake-[votre-id-unique]
     Type d'emplacement : R√©gion
     R√©gion : europe-west1 (Belgique)
     Classe de stockage : Standard
     Contr√¥le d'acc√®s : Uniforme
     Protection : Aucune (pour l'instant)
     ```
   - Cliquer sur "Cr√©er"

2. **Via la CLI** (alternatif) :
   ```bash
   gcloud storage buckets create gs://orangescrum-datalake-unique \
     --location=europe-west1 \
     --uniform-bucket-level-access
   ```

### 4.3 Cr√©er la Structure du Bucket

```bash
# Cr√©er des dossiers virtuels
gsutil mkdir gs://orangescrum-datalake-unique/raw/
gsutil mkdir gs://orangescrum-datalake-unique/processed/
gsutil mkdir gs://orangescrum-datalake-unique/archive/
```

## üìä √âtape 5 : Configurer BigQuery

### 5.1 Activer l'API BigQuery

1. Menu ‚â° ‚Üí "APIs et services" ‚Üí "Biblioth√®que"
2. Rechercher "BigQuery"
3. Cliquer sur "BigQuery API"
4. Cliquer sur "Activer"

### 5.2 Cr√©er un Dataset

1. **Via la Console** :
   - Menu ‚â° ‚Üí "BigQuery" ‚Üí "BigQuery Studio"
   - Dans le panneau de gauche, cliquer sur votre projet
   - Cliquer sur les trois points ‚Üí "Cr√©er un ensemble de donn√©es"
   - Configuration :
     ```
     ID de l'ensemble de donn√©es : orangescrum_dw
     Emplacement : EU (multi-r√©gions)
     Expiration des tables par d√©faut : Jamais
     Chiffrement : Cl√© g√©r√©e par Google
     ```
   - Cliquer sur "Cr√©er un ensemble de donn√©es"

2. **Via la CLI** (alternatif) :
   ```bash
   bq mk --location=EU orangescrum_dw
   ```

### 5.3 Cr√©er une Table de Test

```sql
-- Dans l'√©diteur BigQuery, ex√©cuter :
CREATE TABLE `orangescrum_dw.test_table` (
  id INT64,
  name STRING,
  created_at TIMESTAMP
)
PARTITION BY DATE(created_at);

-- Ins√©rer des donn√©es de test
INSERT INTO `orangescrum_dw.test_table` (id, name, created_at)
VALUES 
  (1, 'Test 1', CURRENT_TIMESTAMP()),
  (2, 'Test 2', CURRENT_TIMESTAMP());

-- V√©rifier
SELECT * FROM `orangescrum_dw.test_table`;
```

## üîß √âtape 6 : Configuration Locale

### 6.1 Mettre √† Jour config.env

```bash
# √âditer le fichier config.env
nano config.env
```

Modifier les valeurs GCP :
```bash
# ==============================================
# GCP Configuration
# ==============================================
GCP_PROJECT_ID=bigdata-orangescrum-123456
GCP_REGION=europe-west1
GCS_BUCKET_NAME=orangescrum-datalake-unique
BIGQUERY_DATASET=orangescrum_dw
GOOGLE_APPLICATION_CREDENTIALS=./credentials/gcp-service-account.json
```

### 6.2 Installer le Google Cloud SDK (optionnel)

**Sur macOS** :
```bash
# Avec Homebrew
brew install --cask google-cloud-sdk

# Initialiser
gcloud init

# Se connecter
gcloud auth login

# Configurer le projet
gcloud config set project bigdata-orangescrum-123456
```

**Sur Linux** :
```bash
# T√©l√©charger et installer
curl https://sdk.cloud.google.com | bash
exec -l $SHELL
gcloud init
```

### 6.3 Tester la Connexion

#### Test GCS

```bash
# Cr√©er un fichier de test
echo "Hello GCS!" > test.txt

# Uploader
gsutil cp test.txt gs://orangescrum-datalake-unique/

# Lister
gsutil ls gs://orangescrum-datalake-unique/

# Supprimer le test
gsutil rm gs://orangescrum-datalake-unique/test.txt
rm test.txt
```

#### Test BigQuery

```bash
# Lister les datasets
bq ls

# Lister les tables
bq ls orangescrum_dw

# Query de test
bq query --use_legacy_sql=false \
  'SELECT COUNT(*) as total FROM `orangescrum_dw.test_table`'
```

## üìà √âtape 7 : Configurer les Alertes de Facturation

### 7.1 Cr√©er un Budget

1. Menu ‚â° ‚Üí "Facturation" ‚Üí "Budgets et alertes"
2. Cliquer sur "Cr√©er un budget"
3. Configuration :
   ```
   Nom : Budget Projet BigData
   Projets : bigdata-orangescrum-123456
   Montant : 10 EUR (ou votre limite souhait√©e)
   ```
4. Alertes :
   ```
   50% du budget : Email
   90% du budget : Email
   100% du budget : Email
   ```
5. Cliquer sur "Terminer"

### 7.2 Surveiller les Co√ªts

```bash
# Via CLI
gcloud billing accounts list
gcloud billing projects describe bigdata-orangescrum-123456

# Via Console
Menu ‚â° ‚Üí Facturation ‚Üí Rapports
```

## üé® √âtape 8 : Configurer Looker Studio

### 8.1 Acc√©der √† Looker Studio

1. URL : https://lookerstudio.google.com
2. Se connecter avec le m√™me compte Google

### 8.2 Cr√©er une Source de Donn√©es

1. Cliquer sur "Cr√©er" ‚Üí "Source de donn√©es"
2. S√©lectionner "BigQuery"
3. Autoriser l'acc√®s
4. S√©lectionner :
   ```
   Projet : bigdata-orangescrum-123456
   Dataset : orangescrum_dw
   Table : test_table (pour commencer)
   ```
5. Cliquer sur "Connecter"

### 8.3 Cr√©er un Premier Dashboard (Test)

1. Cliquer sur "Cr√©er" ‚Üí "Rapport"
2. S√©lectionner la source de donn√©es cr√©√©e
3. Ajouter un graphique de test
4. Cliquer sur "Ajouter au rapport"

## ‚úÖ √âtape 9 : V√©rification Compl√®te

### Checklist

- [ ] Compte GCP cr√©√© avec cr√©dits
- [ ] Projet `bigdata-orangescrum` cr√©√©
- [ ] Service Account cr√©√© avec les bons r√¥les
- [ ] Cl√© JSON t√©l√©charg√©e et plac√©e dans `credentials/`
- [ ] Bucket GCS cr√©√© : `orangescrum-datalake-*`
- [ ] Dataset BigQuery cr√©√© : `orangescrum_dw`
- [ ] Table de test cr√©√©e et fonctionnelle
- [ ] `config.env` mis √† jour avec les bonnes valeurs
- [ ] Google Cloud SDK install√© (optionnel)
- [ ] Tests de connexion GCS r√©ussis
- [ ] Tests de connexion BigQuery r√©ussis
- [ ] Budget et alertes configur√©s
- [ ] Looker Studio connect√© √† BigQuery

### Script de Test Complet

Cr√©er un fichier `scripts/gcp/test_connection.py` :

```python
#!/usr/bin/env python3
"""Test de connexion √† GCP"""

import os
from google.cloud import storage, bigquery

# Charger les credentials
os.environ['GOOGLE_APPLICATION_CREDENTIALS'] = './credentials/gcp-service-account.json'

def test_gcs():
    """Test Google Cloud Storage"""
    print("üß™ Test GCS...")
    try:
        client = storage.Client()
        buckets = list(client.list_buckets())
        print(f"‚úÖ GCS OK - {len(buckets)} bucket(s) trouv√©(s)")
        for bucket in buckets:
            print(f"   ‚Ä¢ {bucket.name}")
        return True
    except Exception as e:
        print(f"‚ùå GCS Error: {e}")
        return False

def test_bigquery():
    """Test BigQuery"""
    print("\nüß™ Test BigQuery...")
    try:
        client = bigquery.Client()
        datasets = list(client.list_datasets())
        print(f"‚úÖ BigQuery OK - {len(datasets)} dataset(s) trouv√©(s)")
        for dataset in datasets:
            print(f"   ‚Ä¢ {dataset.dataset_id}")
        return True
    except Exception as e:
        print(f"‚ùå BigQuery Error: {e}")
        return False

if __name__ == "__main__":
    print("üîç Test de connexion GCP\n")
    gcs_ok = test_gcs()
    bq_ok = test_bigquery()
    
    print("\n" + "="*50)
    if gcs_ok and bq_ok:
        print("‚úÖ Tous les tests sont OK!")
    else:
        print("‚ùå Certains tests ont √©chou√©")
```

Ex√©cuter :
```bash
python3 scripts/gcp/test_connection.py
```

## üÜò D√©pannage

### Erreur : "Permission Denied"

**Solution** :
1. V√©rifier que le Service Account a les bons r√¥les
2. V√©rifier que `GOOGLE_APPLICATION_CREDENTIALS` pointe vers le bon fichier
3. Re-t√©l√©charger la cl√© JSON si n√©cessaire

### Erreur : "Quota Exceeded"

**Solution** :
1. V√©rifier les quotas : Menu ‚â° ‚Üí "IAM" ‚Üí "Quotas"
2. Demander une augmentation si n√©cessaire (g√©n√©ralement pas n√©cessaire en mode gratuit)

### Bucket d√©j√† existant

**Solution** :
- Les noms de buckets GCS sont uniques globalement
- Ajouter un suffixe unique : `orangescrum-datalake-votreprenom`

## üìö Ressources

- [GCP Free Tier](https://cloud.google.com/free)
- [GCP for Students](https://cloud.google.com/edu)
- [BigQuery Sandbox](https://cloud.google.com/bigquery/docs/sandbox)
- [GCS Documentation](https://cloud.google.com/storage/docs)
- [BigQuery Documentation](https://cloud.google.com/bigquery/docs)

---

**Prochaine √©tape** : Retour au README principal pour d√©marrer la plateforme locale !

