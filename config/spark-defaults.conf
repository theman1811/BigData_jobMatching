# ============================================
# Spark Configuration - Default Settings
# ============================================

# ==========================================
# Application Settings
# ==========================================
spark.app.name                BigDataJobMatching
spark.master                  spark://spark-master:7077

# ==========================================
# MinIO / S3 Configuration
# ==========================================
spark.hadoop.fs.s3a.endpoint              http://minio:9000
spark.hadoop.fs.s3a.access.key            minioadmin
spark.hadoop.fs.s3a.secret.key            minioadmin123
spark.hadoop.fs.s3a.path.style.access     true
spark.hadoop.fs.s3a.impl                  org.apache.hadoop.fs.s3a.S3AFileSystem
spark.hadoop.fs.s3a.connection.ssl.enabled false

# S3A Settings
spark.hadoop.fs.s3a.fast.upload           true
spark.hadoop.fs.s3a.multipart.size        104857600
spark.hadoop.fs.s3a.fast.upload.buffer    bytebuffer

# ==========================================
# Memory Settings
# ==========================================
spark.driver.memory                       2g
spark.executor.memory                     2g
spark.memory.fraction                     0.8
spark.memory.storageFraction              0.3

# ==========================================
# Shuffle Settings
# ==========================================
spark.shuffle.compress                    true
spark.shuffle.spill.compress              true
spark.io.compression.codec                snappy

# ==========================================
# Serialization
# ==========================================
spark.serializer                          org.apache.spark.serializer.KryoSerializer
spark.kryoserializer.buffer.max           512m

# ==========================================
# Event Log (pour monitoring)
# ==========================================
spark.eventLog.enabled                    true
spark.eventLog.dir                        /opt/spark-data/logs
spark.history.fs.logDirectory             /opt/spark-data/logs

# ==========================================
# UI Settings
# ==========================================
spark.ui.enabled                          true
spark.ui.port                             4040
spark.ui.showConsoleProgress              true

# ==========================================
# Kafka Settings (for Spark Streaming)
# ==========================================
spark.streaming.kafka.maxRatePerPartition 1000
spark.streaming.backpressure.enabled      true
spark.streaming.receiver.maxRate          1000

# ==========================================
# Dynamic Allocation (optionnel)
# ==========================================
spark.dynamicAllocation.enabled           false
spark.dynamicAllocation.minExecutors      1
spark.dynamicAllocation.maxExecutors      3

# ==========================================
# Network Settings
# ==========================================
spark.network.timeout                     300s
spark.rpc.message.maxSize                 512

# ==========================================
# SQL Settings
# ==========================================
spark.sql.adaptive.enabled                true
spark.sql.adaptive.coalescePartitions.enabled true
spark.sql.parquet.compression.codec       snappy

# ==========================================
# Jars (AWS SDK for S3 support)
# ==========================================
# Note: Ces JARs doivent être téléchargés dans /opt/bitnami/spark/jars/
# - hadoop-aws-3.3.4.jar
# - aws-java-sdk-bundle-1.12.x.jar

