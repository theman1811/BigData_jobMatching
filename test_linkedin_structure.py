#!/usr/bin/env python3
"""
Test de la structure LinkedIn Jobs pour CÃ´te d'Ivoire
Analyse la page de recherche d'emplois
"""

import urllib.request
import urllib.error
import re
from datetime import datetime

def test_linkedin_jobs_structure():
    """Test de la structure des jobs LinkedIn"""

    # URL de recherche d'emplois en CÃ´te d'Ivoire pour l'informatique
    url = "https://www.linkedin.com/jobs/search/?keywords=informatique&location=C%C3%B4te%20d%27Ivoire"
    print(f"ğŸ” Analyse LinkedIn Jobs: {url}")
    print("=" * 60)

    try:
        # Headers pour simuler un navigateur
        headers = {
            'User-Agent': 'Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36',
            'Accept': 'text/html,application/xhtml+xml,application/xml;q=0.9,*/*;q=0.8',
            'Accept-Language': 'fr-FR,fr;q=0.9,en-US;q=0.8,en;q=0.7',
            'Accept-Encoding': 'identity',  # Pas de compression pour debug
            'Cache-Control': 'no-cache',
            'Pragma': 'no-cache',
        }

        req = urllib.request.Request(url, headers=headers)
        with urllib.request.urlopen(req, timeout=30) as response:
            content = response.read().decode('utf-8', errors='ignore')

            print(f"âœ… Status: {response.status}")
            print(f"ğŸ“ Taille: {len(content)} caractÃ¨res")

            # Analyse du contenu
            print("\nğŸ—ï¸ Analyse du contenu...")

            # VÃ©rifier si c'est une page de connexion
            if 'login' in content.lower() or 'sign in' in content.lower():
                print("ğŸ” Page de connexion dÃ©tectÃ©e - authentification requise")
                login_forms = re.findall(r'<form[^>]*>.*?</form>', content, re.DOTALL | re.IGNORECASE)
                print(f"   ğŸ“ Formulaires de login trouvÃ©s: {len(login_forms)}")
                return "REQUIRES_AUTH"

            # Chercher des offres d'emploi
            job_cards = re.findall(r'class="[^"]*job-card[^"]*"', content, re.IGNORECASE)
            print(f"ğŸ’¼ Cartes d'offres trouvÃ©es: {len(job_cards)}")

            # Chercher des mentions d'emplois
            job_mentions = re.findall(r'<[^>]*>([^<]*(?:job|emploi|offre)[^<]*)</[^>]*>', content, re.IGNORECASE)
            print(f"ğŸ“„ Mentions d'emplois: {len(job_mentions)}")
            for i, mention in enumerate(job_mentions[:3]):
                print(f"   {i+1}. {mention.strip()[:50]}...")

            # Chercher des entreprises
            company_mentions = re.findall(r'<[^>]*>([^<]*(?:company|entreprise)[^<]*)</[^>]*>', content, re.IGNORECASE)
            print(f"ğŸ¢ Mentions d'entreprises: {len(company_mentions)}")

            # Chercher des localisations
            location_mentions = re.findall(r'<[^>]*>([^<]*(?:location|lieu|CÃ´te d\'Ivoire|C\.I\.)[^<]*)</[^>]*>', content, re.IGNORECASE)
            print(f"ğŸ“ Mentions de localisation: {len(location_mentions)}")

            # Analyser la structure gÃ©nÃ©rale
            print("\nğŸ›ï¸ Structure gÃ©nÃ©rale:")

            if '<main' in content:
                print("   âœ… Balise <main> trouvÃ©e")
            if '<article' in content:
                print("   âœ… Balise <article> trouvÃ©e")
            if 'data-job-id' in content:
                print("   âœ… Attributs data-job-id trouvÃ©s")
            if 'data-company-name' in content:
                print("   âœ… Attributs data-company-name trouvÃ©s")

            # Chercher les scripts JSON (LinkedIn charge souvent les donnÃ©es en JSON)
            json_scripts = re.findall(r'<script[^>]*type="application/ld\+json"[^>]*>(.*?)</script>', content, re.DOTALL)
            print(f"   ğŸ“‹ Scripts JSON-LD trouvÃ©s: {len(json_scripts)}")

            # Sauvegarder un extrait pour analyse
            excerpt = content[:4000] + "\n\n...[contenu tronquÃ©]..."
            with open('/tmp/linkedin_jobs_structure.html', 'w', encoding='utf-8') as f:
                f.write(excerpt)

            print("\nğŸ’¾ Extrait HTML sauvegardÃ© dans /tmp/linkedin_jobs_structure.html")
            print("ğŸ” Analyse terminÃ©e")

            return "ACCESSIBLE"

    except urllib.error.HTTPError as e:
        print(f"âŒ Erreur HTTP: {e.code}")
        if e.code == 403:
            print("   ğŸš« AccÃ¨s refusÃ© (probablement anti-bot)")
        return "BLOCKED"
    except Exception as e:
        print(f"âŒ Erreur gÃ©nÃ©rale: {e}")
        return "ERROR"

def main():
    print("ğŸ”— Test de structure LinkedIn Jobs CÃ´te d'Ivoire")
    result = test_linkedin_jobs_structure()

    print(f"\nğŸ“Š RÃ©sultat: {result}")

    if result == "REQUIRES_AUTH":
        print("ğŸ“ LinkedIn nÃ©cessite une authentification pour accÃ©der aux offres")
        print("   - Le scraper devra gÃ©rer la connexion automatique")
        print("   - Variables d'environnement nÃ©cessaires: LINKEDIN_EMAIL, LINKEDIN_PASSWORD")
    elif result == "ACCESSIBLE":
        print("âœ… LinkedIn accessible sans authentification basique")
        print("   - Structure analysÃ©e et sauvegardÃ©e")
        print("   - Le scraper peut potentiellement fonctionner")
    elif result == "BLOCKED":
        print("ğŸš« LinkedIn bloque les accÃ¨s non authentifiÃ©s")
        print("   - Authentification Selenium nÃ©cessaire")
    else:
        print("âŒ ProblÃ¨me d'accÃ¨s Ã  LinkedIn")

if __name__ == '__main__':
    main()
